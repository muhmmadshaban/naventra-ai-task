import streamlit as st
import requests
import time

st.set_page_config(page_title="AI Resume Internship Applier", layout="centered")
st.title("ğŸ¯ AI Resume Internship Applier")

# === Session State Initialization ===
for key in ["resume_uploaded", "job_titles", "selected_title", "internships", "result"]:
    if key not in st.session_state:
        st.session_state[key] = None if key == "selected_title" else []

# === Step 0: Upload Resume ===
resume_file = st.file_uploader("ğŸ“„ Upload your resume", type=["pdf", "docx", "txt"])

if resume_file:
    st.success(f"ğŸ“„ Resume `{resume_file.name}` uploaded successfully!")

    if st.button("ğŸš€ Upload & Auto Apply"):
        total_start = time.time()

        try:
            # === Step 1: Resume Parsing ===
            parse_start = time.time()
            with st.spinner("ğŸ“„ Parsing resume..."):
                res = requests.post("http://localhost:8000/analyze-resume", files={"resume": resume_file})
            parse_end = time.time()

            if res.status_code != 200:
                st.error("âŒ Resume parsing failed.")
                st.stop()

            data = res.json()
            if "error" in data:
                st.error(f"âŒ Resume parse error: {data['error']}")
                st.stop()

            st.success(f"âœ… Resume parsed in {parse_end - parse_start:.2f} sec")

            st.session_state.job_titles = data.get("job_titles", [])
            st.session_state.result = data

            if not st.session_state.job_titles:
                st.warning("âš ï¸ No job titles found in resume.")
                st.stop()

            # === Step 2: Auto-select Top Title ===
            st.session_state.selected_title = st.session_state.job_titles[0]
            st.info(f"âœ… Top job title selected: **{st.session_state.selected_title}**")

            # === Step 3: Internship Scraping ===
            scrape_start = time.time()
            with st.spinner("ğŸ” Fetching internships..."):
                response = requests.post(
                    "http://localhost:8000/scrape-jobs",
                    json={"keyword": st.session_state.selected_title}
                )
            scrape_end = time.time()

            if response.status_code != 200:
                st.error("âŒ Internship scraping failed.")
                st.stop()

            jobs = response.json()
            st.session_state.internships = jobs.get("internships", [])

            if not st.session_state.internships:
                st.warning("âš ï¸ No internships found.")
                st.stop()

            st.success(f"ğŸ¯ {len(st.session_state.internships)} internships found in {scrape_end - scrape_start:.2f} sec")

            # === Step 4: Auto Apply ===
            apply_start = time.time()
            with st.spinner("ğŸš€ Applying to top internships..."):
                auto_res = requests.post("http://localhost:8000/auto-apply")
            apply_end = time.time()

            if auto_res.status_code != 200:
                st.error("âŒ Auto-apply API error.")
                st.stop()

            result = auto_res.json()
            if result.get("status") != "success":
                st.error("âŒ Auto-apply failed.")
                st.stop()

            st.success(f"âœ… Application submitted in {apply_end - apply_start:.2f} sec")

            applied_jobs = result.get("applied", [])
            if applied_jobs:
                st.markdown("### âœ… Applied Internships")
                for job in applied_jobs:
                    st.markdown(f"""
                    **{job['title']}** at **{job['company']}**  
                    ğŸ”— [Link]({job['link']})  
                    ğŸ•’ {job['timestamp']}
                    """)

        except Exception as e:
            st.error(f"âŒ Exception occurred: {e}")
            st.stop()

        total_time = time.time() - total_start
        st.info(f"â±ï¸ Total time taken: {total_time:.2f} seconds")
